# ğŸ¤– LLM Agent POC (Groq + Multi-Tool Browser App)

A **browser-based multi-tool reasoning agent** that integrates **Groq LLM API** with **OpenAI-style tool calling** and connects to three tools:

- ğŸ” **Google Search** â€“ fetch fresh web snippets using Google Custom Search API  
- ğŸ”„ **AI Pipe API** â€“ workflow-style transforms (proxy or built-in mock)  
- ğŸ’» **Code Execution** â€“ run JavaScript in a secure browser sandbox  

**Features:**
- Clean Bootstrap UI (responsive)  
- Multi-model routing: one model for planning, another for final answer  
- System prompt support for behavioral control  
- Tool loop: LLM calls tools repeatedly until the task is complete  
- One-click deploy on **Render** (no Dockerfile required)  

---

## ğŸ“‘ Table of Contents
- [Demo](#demo)  
- [Architecture](#architecture)  
- [Tools](#tools)  
- [Installation](#installation)  
- [Environment Variables](#environment-variables)  
- [Run Locally](#run-locally)  
- [Deploy to Render](#deploy-to-render)  
- [Usage](#usage)  
- [Customizing System Prompt](#customizing-system-prompt)  
- [Screenshots](#screenshots)  
- [Credits](#credits)  

---

## ğŸš€ Demo

Once deployed, open:  https://<your-render-service>.onrender.com


Browser (UI)
â”œâ”€ Bootstrap UI + Chat Window
â”œâ”€ Web Worker for safe JS execution
â””â”€ fetch() -> Express API

Express Server
â”œâ”€ /api/chat â†’ proxies Groq LLM (OpenAI-style)
â”œâ”€ /api/search â†’ calls Google Custom Search API
â”œâ”€ /api/aipipe â†’ AI Pipe proxy or mock
â””â”€ static â†’ serves index.html



### Flow:
- Messages = [system + user + assistant + tool]  
- Sent to `/api/chat` â†’ Groq â†’ model may request tools  
- If tool calls present â†’ frontend executes tools â†’ sends tool responses  
- Repeat until no more tools â†’ optional **final pass** with larger model for polished answer  

---

## ğŸ”Œ Tools

### 1. ğŸ” Google Search
- Uses [Google Programmable Search Engine](https://programmablesearchengine.google.com/) + [Custom Search JSON API](https://developers.google.com/custom-search/v1/overview)  
- Enable â€œSearch entire webâ€ in PSE  
- Requires `GOOGLE_API_KEY` and `GOOGLE_CSE_ID`  

### 2. ğŸ”„ AI Pipe API
- **Proxy mode:** Set `AIPIPE_URL` to real service  
- **Mock mode:** Leave empty â†’ returns a helpful mock  

### 3. ğŸ’» Code Execution
- Runs user-provided JS code inside a **Web Worker**  
- Isolated, no DOM/network access â†’ safe sandbox  
- Example:




---

## âš™ Installation

Clone the repo:

```bash
git clone https://github.com/yourusername/llm-agent-groq.git
cd llm-agent-groq
npm install


## ğŸ”‘ Environment Variables

Create .env or set on Render:

PORT=7860
DEFAULT_MODEL=llama-3.1-70b-versatile

# Required
GROQ_API_KEY=your_groq_api_key_here

# Optional for Google Search tool
GOOGLE_API_KEY=your_google_api_key
GOOGLE_CSE_ID=your_custom_search_cx

# Optional for AI Pipe tool
AIPIPE_URL=https://aipipe.example.com/run



ğŸ§‘â€ğŸ’» Usage

Choose a model (Groq offers LLaMA, Mixtral, Gemma, etc.).

(Optional) Toggle multi-model mode: small model plans tool usage; large model writes polished final answer.

Add a system prompt (behavior instructions). Example:

You are a tool-using assistant.
- Use `search` for fresh info from the web.
- Use `aipipe` for workflow-style transforms.
- Use `exec_js` for quick calculations or scripts.
After each tool, explain what you learned. Stop when the task is complete.
