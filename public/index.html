<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>LLM Agent POC</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- Bootstrap -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
  <script defer src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js"></script>
  <!-- Optional helper to populate models (fallbacks preserved) -->
  <script defer src="https://cdn.jsdelivr.net/gh/sanand0/bootstrap-llm-provider/dist/bootstrap-llm-provider.min.js"></script>
  <link rel="icon" href="/favicon.svg" type="image/svg+xml">
  <style>
    body { background:#fff; }
    header h1 { font-weight:700; }
    .lead { color:#555; }
    .panel { background:#fff; border:1px solid #e5e7eb; border-radius:.5rem; }
    #chatWindow { height:420px; overflow-y:auto; background:#fafafa; border:1px solid #e5e7eb; border-radius:.5rem; padding:1rem; }
    .msg { border-radius:.5rem; padding:.6rem .8rem; margin-bottom:.6rem; white-space:pre-wrap; }
    .msg.agent { background:#f5e9ff; color:#4a2c6a; }
    .msg.user  { background:#eaf4ff; color:#0b3a6f; margin-left:auto; }
    .msg.tool  { background:#f6f8fa; border:1px dashed #d0d7de; color:#333; }
    .label { font-weight:600; margin-bottom:.25rem; }
    .badge-tool { font-size:.8rem; }
  </style>
</head>
<body>
  <div class="container py-4">
    <!-- Title block (matches your screenshots) -->
    <header class="mb-3">
      <h1 class="mb-1">ü§ñ LLM Agent POC</h1>
      <p class="lead">Browser-based multi-tool reasoning agent with search, AI workflows, and code execution.</p>
    </header>

    <!-- Model + System -->
    <div class="row g-3">
      <div class="col-md-6">
        <div class="label">Model</div>
        <select id="modelMain" class="form-select">
          <!-- Popular Groq models -->
          <option value="llama-3.1-70b-versatile" selected>llama-3.1-70b-versatile</option>
          <option value="llama-3.1-8b-instant">llama-3.1-8b-instant</option>
          <option value="mixtral-8x7b-32768">mixtral-8x7b-32768</option>
          <option value="gemma2-9b-it">gemma2-9b-it</option>
          <option value="llama-guard-3-8b">llama-guard-3-8b (safety)</option>
        </select>
      </div>
      <div class="col-md-6">
        <div class="label">System prompt (optional)</div>
        <input id="systemPrompt" class="form-control" placeholder="You are a helpful agent that uses tools when needed.">
      </div>
    </div>

    <!-- Multi-model (planner + final) -->
    <div class="row g-3 mt-2">
      <div class="col-md-12">
        <div class="form-check">
          <input class="form-check-input" type="checkbox" id="multiModelToggle">
          <label class="form-check-label" for="multiModelToggle">
            Use different model for tool planning and final answer
          </label>
        </div>
      </div>
      <div id="multiModelRow" class="col-md-12" style="display:none;">
        <div class="row g-3">
          <div class="col-md-6">
            <div class="label">Planning model</div>
            <select id="modelPlanner" class="form-select">
              <option value="llama-3.1-8b-instant" selected>llama-3.1-8b-instant (fast)</option>
              <option value="llama-3.1-70b-versatile">llama-3.1-70b-versatile</option>
              <option value="mixtral-8x7b-32768">mixtral-8x7b-32768</option>
              <option value="gemma2-9b-it">gemma2-9b-it</option>
            </select>
          </div>
          <div class="col-md-6">
            <div class="label">Final answer model</div>
            <select id="modelAnswer" class="form-select">
              <option value="llama-3.1-70b-versatile" selected>llama-3.1-70b-versatile</option>
              <option value="mixtral-8x7b-32768">mixtral-8x7b-32768</option>
              <option value="gemma2-9b-it">gemma2-9b-it</option>
            </select>
          </div>
        </div>
      </div>
    </div>

    <!-- Conversation -->
    <div class="mt-4 panel p-3">
      <h4 class="mb-3">Agent Conversation</h4>
      <div id="chatWindow" class="mb-3">
        <div class="msg agent"><strong>Agent:</strong> Hello! I'm your LLM agent with access to web search, AI workflows, and code execution. What can I help you with today?</div>
      </div>
      <div class="input-group">
        <input id="userInput" class="form-control" placeholder="Type your message...">
        <button id="sendBtn" class="btn btn-primary">Send</button>
      </div>
      <div class="mt-2">
        <span class="badge text-bg-secondary badge-tool">üîç search</span>
        <span class="badge text-bg-secondary badge-tool">üîÑ aipipe</span>
        <span class="badge text-bg-secondary badge-tool">üíª exec_js</span>
        <span id="typing" class="ms-2 text-muted" style="display:none;">Agent is thinking‚Ä¶</span>
      </div>
    </div>

    <!-- Alerts -->
    <div id="alerts" class="mt-3"></div>
  </div>

<script>
/* ===== UI refs ===== */
const modelMain = document.getElementById("modelMain");
const systemPrompt = document.getElementById("systemPrompt");
const userInput = document.getElementById("userInput");
const sendBtn = document.getElementById("sendBtn");
const chatWindow = document.getElementById("chatWindow");
const alerts = document.getElementById("alerts");
const typing = document.getElementById("typing");
const multiModelToggle = document.getElementById("multiModelToggle");
const multiModelRow = document.getElementById("multiModelRow");
const modelPlanner = document.getElementById("modelPlanner");
const modelAnswer = document.getElementById("modelAnswer");

multiModelToggle.addEventListener("change", () => {
  multiModelRow.style.display = multiModelToggle.checked ? "" : "none";
});

function addMsg(kind, text) {
  const el = document.createElement("div");
  el.className = "msg " + (kind === "user" ? "user" : kind === "tool" ? "tool" : "agent");
  el.innerHTML = `<strong>${kind === "user" ? "You" : kind === "tool" ? "Tool" : "Agent"}:</strong> ${escapeHtml(text)}`;
  chatWindow.appendChild(el);
  chatWindow.scrollTop = chatWindow.scrollHeight;
}
function addToolHtml(title, html) {
  const el = document.createElement("div");
  el.className = "msg tool";
  el.innerHTML = `<strong>${escapeHtml(title)}:</strong><div class="mt-2">${html}</div>`;
  chatWindow.appendChild(el);
  chatWindow.scrollTop = chatWindow.scrollHeight;
}
function escapeHtml(s){ return String(s).replace(/[&<>"']/g, m => ({'&':'&amp;','<':'&lt;','>':'&gt;','"':'&quot;',"'":'&#039;'}[m])); }
function showAlert(html, type="warning", ms=4000) {
  const id = "al_" + Math.random().toString(36).slice(2);
  alerts.insertAdjacentHTML("beforeend", `<div id="${id}" class="alert alert-${type} alert-dismissible fade show" role="alert">${html}<button type="button" class="btn-close" data-bs-dismiss="alert"></button></div>`);
  setTimeout(()=>document.getElementById(id)?.remove(), ms);
}
function setThinking(on){ typing.style.display = on ? "" : "none"; }

/* ===== Web Worker sandbox for JS ===== */
function runInWorker(code) {
  return new Promise((resolve) => {
    const blob = new Blob([`
      self.onmessage = (e) => {
        try {
          const result = (async () => { ${e.data} })();
          Promise.resolve(result).then(
            v => self.postMessage({ ok:true, result:String(v) }),
            e => self.postMessage({ ok:false, error:String(e?.message||e) })
          );
        } catch (err) {
          self.postMessage({ ok:false, error:String(err?.message||err) });
        }
      };`], { type: "application/javascript" });
    const worker = new Worker(URL.createObjectURL(blob));
    worker.onmessage = (e) => {
      resolve(e.data.ok ? e.data.result : "Error: "+e.data.error);
      worker.terminate();
    };
    worker.postMessage(code);
  });
}

/* ===== Tools: handlers (frontend; /api/* on server) ===== */
async function tool_search(params) {
  const q = params?.q || "";
  const r = await fetch(`/api/search?q=${encodeURIComponent(q)}`);
  if (!r.ok) throw new Error(`search failed (${r.status})`);
  const d = await r.json();
  const html = (d.items||[]).slice(0,5).map(it =>
    `<div class="mb-2"><a href="${it.link}" target="_blank">${escapeHtml(it.title)}</a><div class="text-muted small">${escapeHtml(it.snippet||"")}</div></div>`
  ).join("") || "<div class='text-muted small'>No results.</div>";
  addToolHtml(`search("${q}")`, html);
  return d;
}
async function tool_aipipe(params) {
  const r = await fetch("/api/aipipe", {
    method:"POST", headers:{ "Content-Type":"application/json" },
    body: JSON.stringify(params || {})
  });
  if (!r.ok) throw new Error(`aipipe failed (${r.status})`);
  const d = await r.json();
  addToolHtml("aipipe()", `<pre class="mb-0">${escapeHtml(JSON.stringify(d, null, 2))}</pre>`);
  return d;
}
async function tool_exec_js(params) {
  const out = await runInWorker(params?.code || "");
  addToolHtml("exec_js()", `<pre class="mb-0">${escapeHtml(out)}</pre>`);
  return { output: out };
}
const TOOL_MAP = { search: tool_search, aipipe: tool_aipipe, exec_js: tool_exec_js };

/* ===== OpenAI-style tool schema for Groq ===== */
const TOOL_DECLS = [
  {
    type: "function", function: {
      name: "search",
      description: "Google search snippets",
      parameters: { type:"object", properties:{ q:{ type:"string" } }, required:["q"] }
    }
  },
  {
    type: "function", function: {
      name: "aipipe",
      description: "Call an AI Pipe workflow",
      parameters: { type:"object", properties:{ input:{ type:"string" } }, required:["input"] }
    }
  },
  {
    type: "function", function: {
      name: "exec_js",
      description: "Execute JavaScript in a Web Worker and return output",
      parameters: { type:"object", properties:{ code:{ type:"string" } }, required:["code"] }
    }
  }
];

/* ===== Chat call (Groq via our server) ===== */
async function callGroq(model, messages, withTools=true) {
  const body = {
    model,
    messages,
    temperature: 0.3,
    ...(withTools ? { tools: TOOL_DECLS } : {})
  };
  const r = await fetch("/api/chat", {
    method:"POST",
    headers:{ "Content-Type":"application/json" },
    body: JSON.stringify(body)
  });
  if (!r.ok) {
    const t = await r.text();
    throw new Error(`chat error ${r.status}: ${t}`);
  }
  return r.json();
}

/* ===== Agent loop (multi-tool, multi-model) ===== */
async function runAgent(userText) {
  const messages = [];
  const sys = systemPrompt.value.trim();
  const singleModel   = !multiModelToggle.checked;
  const plannerModel  = singleModel ? modelMain.value : modelPlanner.value;
  const answerModel   = singleModel ? modelMain.value : modelAnswer.value;

  if (sys) messages.push({ role:"system", content: sys });
  messages.push({ role:"user", content: userText });
  addMsg("user", userText);

  setThinking(true);
  try {
    let keepLooping = true;
    while (keepLooping) {
      // Planning/model that can call tools
      const data = await callGroq(plannerModel, messages, true);
      const msg  = data.choices?.[0]?.message || {};
      if (msg.content) {
        addMsg("agent", msg.content);
        messages.push({ role:"assistant", content: msg.content });
      }

      const toolCalls = msg.tool_calls || [];
      if (!toolCalls.length) {
        keepLooping = false;
        break;
      }

      // Execute each tool call
      for (const tc of toolCalls) {
        const name = tc.function?.name;
        const argsJson = tc.function?.arguments;
        let args = {};
        try { args = argsJson ? JSON.parse(argsJson) : {}; } catch {}
        try {
          const handler = TOOL_MAP[name];
          if (!handler) throw new Error(`Unknown tool: ${name}`);
          const result = await handler(args);
          messages.push({ role:"tool", tool_call_id: tc.id, name, content: JSON.stringify(result) });
        } catch (err) {
          showAlert(`Tool ${name} error: ${escapeHtml(err.message)}`, "danger");
          messages.push({ role:"tool", tool_call_id: tc.id, name, content: JSON.stringify({ error: err.message }) });
        }
      }
    }

    // Optional second pass: final answer with a larger model (no tools)
    if (!singleModel) {
      const data2 = await callGroq(answerModel, messages, false);
      const msg2  = data2.choices?.[0]?.message;
      if (msg2?.content) {
        addMsg("agent", msg2.content);
        messages.push({ role:"assistant", content: msg2.content });
      }
    }
  } catch (err) {
    showAlert(`Agent error: ${escapeHtml(err.message)}`, "danger");
  } finally {
    setThinking(false);
  }
}

/* ===== Wire up ===== */
sendBtn.addEventListener("click", () => {
  const text = userInput.value.trim();
  if (!text) return;
  userInput.value = "";
  runAgent(text);
});
userInput.addEventListener("keydown", (e) => { if (e.key === "Enter") sendBtn.click(); });

/* Optional: populate via helper (keeps our defaults if not available) */
(async () => {
  try {
    await bootstrapLLMProvider.populate(modelMain);
    await bootstrapLLMProvider.populate(modelPlanner);
    await bootstrapLLMProvider.populate(modelAnswer);
  } catch {}
})();
</script>
</body>
</html>
