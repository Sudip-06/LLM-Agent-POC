<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>LLM Agent POC ‚Äî Groq & Gemini</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <!-- Bootstrap -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
  <script defer src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/js/bootstrap.bundle.min.js"></script>
  <!-- Optional helper (keeps our defaults if not available) -->
  <script defer src="https://cdn.jsdelivr.net/gh/sanand0/bootstrap-llm-provider/dist/bootstrap-llm-provider.min.js"></script>
  <link rel="icon" href="/favicon.svg" type="image/svg+xml">
  <style>
    body { background:#fff; }
    header h1 { font-weight:700; }
    .lead { color:#555; }
    .panel { background:#fff; border:1px solid #e5e7eb; border-radius:.5rem; }
    #chatWindow { height:420px; overflow-y:auto; background:#fafafa; border:1px solid #e5e7eb; border-radius:.5rem; padding:1rem; }
    .msg { border-radius:.5rem; padding:.6rem .8rem; margin-bottom:.6rem; white-space:pre-wrap; }
    .msg.agent { background:#f5e9ff; color:#4a2c6a; }
    .msg.user  { background:#eaf4ff; color:#0b3a6f; margin-left:auto; }
    .msg.tool  { background:#f6f8fa; border:1px dashed #d0d7de; color:#333; }
    .label { font-weight:600; margin-bottom:.25rem; }
    .badge-tool { font-size:.8rem; }
  </style>
</head>
<body>
  <div class="container py-4">
    <header class="mb-3">
      <h1 class="mb-1">ü§ñ LLM Agent POC</h1>
      <p class="lead">Dual-provider (Groq & Gemini) multi-tool agent with search, AI workflows, and code execution.</p>
    </header>

    <!-- Provider + Model + System -->
    <div class="row g-3">
      <div class="col-md-3">
        <div class="label">Provider</div>
        <select id="provider" class="form-select">
          <option value="gemini" selected>Gemini</option>
          <option value="groq">Groq (gorq)</option>
          
        </select>
      </div>
      <div class="col-md-5">
        <div class="label">Model</div>
        <select id="modelMain" class="form-select"></select>
      </div>
      <div class="col-md-4">
        <div class="label">System prompt</div>
        <input id="systemPrompt" class="form-control"
          value="">
      </div>
    </div>

    <!-- Multi-model (planner + final) -->
    <div class="row g-3 mt-2">
      <div class="col-md-12">
        <div class="form-check">
          <input class="form-check-input" type="checkbox" id="multiModelToggle">
          <label class="form-check-label" for="multiModelToggle">
            Use different model for tool planning and final answer
          </label>
        </div>
      </div>
      <div id="multiModelRow" class="col-md-12" style="display:none;">
        <div class="row g-3">
          <div class="col-md-6">
            <div class="label">Planning model</div>
            <select id="modelPlanner" class="form-select"></select>
          </div>
          <div class="col-md-6">
            <div class="label">Final answer model</div>
            <select id="modelAnswer" class="form-select"></select>
          </div>
        </div>
      </div>
    </div>

    <!-- Conversation -->
    <div class="mt-4 panel p-3">
      <h4 class="mb-3">Agent Conversation</h4>
      <div id="chatWindow" class="mb-3">
        <div class="msg agent"><strong>Agent:</strong> Hello! I can use web search, AI workflows, and code execution. Ask me anything.</div>
      </div>
      <div class="input-group">
        <input id="userInput" class="form-control" placeholder="Type your message...">
        <button id="sendBtn" class="btn btn-primary">Send</button>
      </div>
      <div class="mt-2">
        <span class="badge text-bg-secondary badge-tool">üîç search</span>
        <span class="badge text-bg-secondary badge-tool">üîÑ aipipe</span>
        <span class="badge text-bg-secondary badge-tool">üíª exec_js</span>
        <span id="typing" class="ms-2 text-muted" style="display:none;">Agent is thinking‚Ä¶</span>
      </div>
    </div>

    <!-- Alerts -->
    <div id="alerts" class="mt-3"></div>
  </div>

<script>
/* =========================
   UI refs
========================= */
const providerSel   = document.getElementById("provider");
const modelMain     = document.getElementById("modelMain");
const systemPrompt  = document.getElementById("systemPrompt");
const userInput     = document.getElementById("userInput");
const sendBtn       = document.getElementById("sendBtn");
const chatWindow    = document.getElementById("chatWindow");
const alerts        = document.getElementById("alerts");
const typing        = document.getElementById("typing");
const multiModelToggle = document.getElementById("multiModelToggle");
const multiModelRow    = document.getElementById("multiModelRow");
const modelPlanner  = document.getElementById("modelPlanner");
const modelAnswer   = document.getElementById("modelAnswer");

multiModelToggle.addEventListener("change", () => {
  multiModelRow.style.display = multiModelToggle.checked ? "" : "none";
});

/* =========================
   Model lists per provider
========================= */
const GROQ_MODELS = [
  "openai/gpt-oss-120b",
  "openai/gpt-oss-20b",
  "qwen/qwen3-32b",
  "deepseek-r1-distill-llama-70b"
];

const GEMINI_MODELS = [
  "gemini-2.5-flash",
  "gemini-2.5-pro"
];

function populateModels() {
  const prov = providerSel.value;
  const list = prov === "gemini" ? GEMINI_MODELS : GROQ_MODELS;
  function fill(select) {
    select.innerHTML = "";
    list.forEach((m, i) => {
      const opt = document.createElement("option");
      opt.value = m;
      opt.textContent = m + (i === 0 ? " (default)" : "");
      if (i === 0) opt.selected = true;
      select.appendChild(opt);
    });
  }
  fill(modelMain);
  fill(modelPlanner);
  fill(modelAnswer);
}
providerSel.addEventListener("change", populateModels);
populateModels();

/* =========================
   Helpers
========================= */
function addMsg(kind, text) {
  const el = document.createElement("div");
  el.className = "msg " + (kind === "user" ? "user" : kind === "tool" ? "tool" : "agent");
  el.innerHTML = `<strong>${kind === "user" ? "You" : kind === "tool" ? "Tool" : "Agent"}:</strong> ${escapeHtml(text)}`;
  chatWindow.appendChild(el);
  chatWindow.scrollTop = chatWindow.scrollHeight;
}
function addToolHtml(title, html) {
  const el = document.createElement("div");
  el.className = "msg tool";
  el.innerHTML = `<strong>${escapeHtml(title)}:</strong><div class="mt-2">${html}</div>`;
  chatWindow.appendChild(el);
  chatWindow.scrollTop = chatWindow.scrollHeight;
}
function escapeHtml(s){ return String(s).replace(/[&<>"']/g, m => ({'&':'&amp;','<':'&lt;','>':'&gt;','"':'&quot;',"'":'&#039;'}[m])); }
function showAlert(html, type="warning", ms=5000) {
  const id = "al_" + Math.random().toString(36).slice(2);
  alerts.insertAdjacentHTML("beforeend", `<div id="${id}" class="alert alert-${type} alert-dismissible fade show" role="alert">${html}<button type="button" class="btn-close" data-bs-dismiss="alert"></button></div>`);
  setTimeout(()=>document.getElementById(id)?.remove(), ms);
}
function setThinking(on){ typing.style.display = on ? "" : "none"; }

/* Remove raw function-call echoes like "<function=aipipe>{...}" */
function cleanAssistantContent(text) {
  if (!text) return "";
  const lines = text.split(/\r?\n/).filter(line => !/^<\s*function\s*=/.test(line.trim()));
  return lines.join("\n").trim();
}

/* Nicer AI Pipe result card */
function renderAIPipeCard(d) {
  const stepsHtml = (d.steps || []).map(s =>
    `<li>${escapeHtml(s.name)} ‚Äî <span class="badge bg-${s.status === "ok" ? "success" : "danger"}">${escapeHtml(s.status)}</span></li>`
  ).join("") || "<li><em>No steps.</em></li>";
  return `
  <div class="card border-0" style="background:#f6f8fa">
    <div class="card-body p-3">
      <div class="d-flex justify-content-between align-items-center">
        <strong>AI Pipe</strong>
        <span class="badge text-bg-secondary">${escapeHtml(d.engine || "n/a")}</span>
      </div>
      <div class="small text-muted mt-1">${escapeHtml(d.timestamp || "")}</div>
      <div class="mt-2"><strong>Input:</strong> ${escapeHtml(d.received_input || "")}</div>
      <div class="mt-2"><strong>Summary:</strong> ${escapeHtml(d.summary || "")}</div>
      <div class="mt-2"><strong>Steps:</strong>
        <ul class="mt-1 mb-0">${stepsHtml}</ul>
      </div>
    </div>
  </div>`;
}

/* =========================
   Web Worker sandbox (exec_js)
========================= */
function runInWorker(code) {
  return new Promise((resolve) => {
    const blob = new Blob([`
      self.onmessage = (e) => {
        try {
          const result = (async () => { ${e.data} })();
          Promise.resolve(result).then(
            v => self.postMessage({ ok:true, result:String(v) }),
            e => self.postMessage({ ok:false, error:String(e?.message||e) })
          );
        } catch (err) {
          self.postMessage({ ok:false, error:String(err?.message||err) });
        }
      };`], { type: "application/javascript" });
    const worker = new Worker(URL.createObjectURL(blob));
    worker.onmessage = (e) => {
      resolve(e.data.ok ? e.data.result : "Error: "+e.data.error);
      worker.terminate();
    };
    worker.postMessage(code);
  });
}

/* =========================
   Tools (frontend; /api/* on server)
========================= */
async function tool_search(params) {
  const q = params?.q || "";
  const r = await fetch(`/api/search?q=${encodeURIComponent(q)}`);
  if (!r.ok) throw new Error(`search failed (${r.status})`);
  const d = await r.json();
  const html = (d.items||[]).slice(0,5).map(it =>
    `<div class="mb-2"><a href="${it.link}" target="_blank">${escapeHtml(it.title)}</a><div class="text-muted small">${escapeHtml(it.snippet||"")}</div></div>`
  ).join("") || "<div class='text-muted small'>No results.</div>";
  addToolHtml(`search("${q}")`, html);
  return d;
}
async function tool_aipipe(params) {
  const r = await fetch("/api/aipipe", {
    method:"POST", headers:{ "Content-Type":"application/json" },
    body: JSON.stringify(params || {})
  });
  if (!r.ok) throw new Error(`aipipe failed (${r.status})`);
  const d = await r.json();
  addToolHtml("aipipe()", renderAIPipeCard(d));
  return d;
}
async function tool_exec_js(params) {
  const out = await runInWorker(params?.code || "");
  addToolHtml("exec_js()", `<pre class="mb-0">${escapeHtml(out)}</pre>`);
  return { output: out };
}
const TOOL_MAP = { search: tool_search, aipipe: tool_aipipe, exec_js: tool_exec_js };

/* =========================
   OpenAI-style tool schema
========================= */
const TOOL_DECLS = [
  {
    type: "function", function: {
      name: "search",
      description: "Google search snippets",
      parameters: { type:"object", properties:{ q:{ type:"string" } }, required:["q"] }
    }
  },
  {
    type: "function", function: {
      name: "aipipe",
      description: "Call an AI Pipe workflow",
      parameters: { type:"object", properties:{ input:{ type:"string" } }, required:["input"] }
    }
  },
  {
    type: "function", function: {
      name: "exec_js",
      description: "Execute JavaScript in a Web Worker and return output",
      parameters: { type:"object", properties:{ code:{ type:"string" } }, required:["code"] }
    }
  }
];

/* =========================
   Provider-aware chat call
========================= */
async function callLLM(provider, model, messages, withTools=true) {
  const base = { model, messages, temperature: 0.3 };
  const body = withTools ? { ...base, tools: TOOL_DECLS } : base;

  const url = provider === "gemini" ? "/api/gemini/chat" : "/api/groq/chat";
  const payload = provider === "gemini"
    ? { ...body, system: (messages.find(m => m.role === "system")?.content) || "" }
    : body;

  const r = await fetch(url, {
    method:"POST",
    headers:{ "Content-Type":"application/json" },
    body: JSON.stringify(payload)
  });
  if (!r.ok) {
    const t = await r.text();
    throw new Error(`${provider} chat error ${r.status}: ${t}`);
  }
  return r.json();
}

/* =========================
   Agent loop
========================= */
async function runAgent(userText) {
  const provider = providerSel.value;
  const messages = [];
  const sys = systemPrompt.value.trim();
  const singleModel   = !multiModelToggle.checked;
  const plannerModel  = singleModel ? modelMain.value : modelPlanner.value;
  const answerModel   = singleModel ? modelMain.value : modelAnswer.value;

  if (sys) messages.push({ role:"system", content: sys });
  messages.push({ role:"user", content: userText });
  addMsg("user", userText);

  setThinking(true);
  const seenToolCalls = new Set(); // de-dupe same id/name/args in a turn

  try {
    let keepLooping = true;
    while (keepLooping) {
      const data = await callLLM(provider, plannerModel, messages, true);
      const msg  = data.choices?.[0]?.message || {};

      const cleaned = cleanAssistantContent(msg.content || "");
      if (cleaned) {
        addMsg("agent", cleaned);
        messages.push({ role:"assistant", content: cleaned });
      }

      const toolCalls = msg.tool_calls || [];
      if (!toolCalls.length) {
        keepLooping = false;
        break;
      }

      for (const tc of toolCalls) {
        const name = tc.function?.name;
        const argsJson = tc.function?.arguments;
        const sig = (tc.id || "") + "|" + name + "|" + (argsJson || "");
        if (seenToolCalls.has(sig)) continue; // skip repeated calls
        seenToolCalls.add(sig);

        let args = {};
        try { args = argsJson ? JSON.parse(argsJson) : {}; } catch {}

        try {
          const handler = TOOL_MAP[name];
          if (!handler) throw new Error(`Unknown tool: ${name}`);
          const result = await handler(args);
          messages.push({ role:"tool", tool_call_id: tc.id, name, content: JSON.stringify(result) });
        } catch (err) {
          showAlert(`Tool ${name} error: ${escapeHtml(err.message)}`, "danger");
          messages.push({ role:"tool", tool_call_id: tc.id, name, content: JSON.stringify({ error: err.message }) });
        }
      }
    }

    // Optional second pass for final, polished answer (no tools)
    if (!singleModel) {
      const data2 = await callLLM(provider, answerModel, messages, false);
      const msg2  = data2.choices?.[0]?.message;
      if (msg2?.content) {
        addMsg("agent", msg2.content);
        messages.push({ role:"assistant", content: msg2.content });
      }
    }
  } catch (err) {
    showAlert(`Agent error: ${escapeHtml(err.message)}`, "danger");
  } finally {
    setThinking(false);
  }
}

/* =========================
   Wire up UI
========================= */
sendBtn.addEventListener("click", () => {
  const text = userInput.value.trim();
  if (!text) return;
  userInput.value = "";
  runAgent(text);
});
userInput.addEventListener("keydown", (e) => { if (e.key === "Enter") sendBtn.click(); });

/* Optional: helper population (keeps our defaults if not available) */
(async () => {
  try {
    await bootstrapLLMProvider.populate(modelMain);
    await bootstrapLLMProvider.populate(modelPlanner);
    await bootstrapLLMProvider.populate(modelAnswer);
  } catch {}
})();
</script>
</body>
</html>
